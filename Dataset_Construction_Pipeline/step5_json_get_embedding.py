# -*- coding: utf-8 -*-
"""json get embedding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mWF9Y63jyF7ZkYnwH0StOmLOkiSYGN02
"""

import os
import time
import json
from openai import OpenAI
import openai

os.environ['OPENAI_BASE_URL'] = "https://xxx.ADDyourGPTapi.com"
os.environ['OPENAI_API_KEY'] = 'sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'
client = OpenAI()


def get_embedding(text, model="text-embedding-3-large"):
    text = text.replace("\n", " ")
    return client.embeddings.create(input=[text], model=model, dimensions=128).data[0].embedding  # 128 is fixed


def process_json_files(source_directory, target_directory):
    if not os.path.exists(target_directory):
        os.makedirs(target_directory)
        print(f"Created target directory: {target_directory}")

    for filename in os.listdir(source_directory):
        if filename.endswith('.json'):
            source_file_path = os.path.join(source_directory, filename)
            target_file_path = os.path.join(target_directory, filename)
            if os.path.exists(target_file_path):
                print(f"File {target_file_path} already exists. Skipping.")
                continue

            print(f"Processing file: {source_file_path}")

            try:
                with open(source_file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                trend_analysis = data.get("Trend Analysis", "")
                if not trend_analysis:
                    print(f"No 'Trend Analysis' field found in {filename}. Skipping.")
                    continue

                start_time = time.time()
                embedding = get_embedding(trend_analysis)
                end_time = time.time()
                if embedding is None:
                    print(f"Failed to get embedding for {filename}. Skipping.")
                    continue

                data["embedding"] = embedding

                with open(target_file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=4)

                print(
                    f"Successfully updated and saved {filename} to {target_directory}.cost time:{end_time - start_time}")

            except Exception as e:
                print(f"Error processing file {filename}: {e}")


dataset_name_index = 1
sample_length_index = 0
dataset_name_list = ['ETTh1', 'ETTm1', 'electricity', 'exchange_rate', 'traffic', 'air-quality']
dataset_name = dataset_name_list[dataset_name_index]
target_column_name = 'OT'
sample_length_list = [24, 48, 96]  #
sample_length = sample_length_list[sample_length_index]
source_directory = f'./{dataset_name}_{sample_length}_folder/json_data'
target_directory = f'./json_data_{dataset_name}_1029_small_embedding_{sample_length}'

process_json_files(source_directory, target_directory)
